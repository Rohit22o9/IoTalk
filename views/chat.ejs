<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chat with <%= otherUser.username %> - ModernChat</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="/style.css">
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            primary: {
              50: '#eff6ff', 100: '#dbeafe',
              500: '#3b82f6', 600: '#2563eb',
              700: '#1d4ed8', 800: '#1e40af', 900: '#1e3a8a',
            },
            secondary: {
              50: '#f8fafc', 100: '#f1f5f9',
              500: '#64748b', 600: '#475569',
              700: '#334155', 800: '#1e293b', 900: '#0f172a',
            }
          }
        }
      }
    }
  </script>
  <style>
    body, html {
      overflow-x: hidden;
    }
    .chat-messages {
      overflow-x: hidden;
      word-wrap: break-word;
      word-break: break-word;
    }
  </style>
</head>

<body class="h-screen bg-gradient-to-br from-secondary-50 via-white to-primary-50 overflow-hidden">
  <div class="h-full flex flex-col relative">
    <!-- Header -->
    <header class="bg-white/90 backdrop-blur-lg border-b border-secondary-200 px-4 py-3 flex-shrink-0">
      <div class="flex items-center space-x-4">
        <form action="/dashboard" method="GET" class="inline">
          <button type="submit" class="p-2 rounded-lg hover:bg-secondary-100 transition-colors duration-200">
            <svg class="h-5 w-5 text-secondary-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path>
            </svg>
          </button>
        </form>
        <div class="flex items-center space-x-3 flex-1">
          <img src="<%= otherUser.avatar || '/avatars/default-avatar.png' %>"
               alt="<%= otherUser.username %>"
               class="w-10 h-10 rounded-full object-cover border-2 border-white shadow-md">
          <div>
            <h1 class="text-lg font-semibold text-secondary-900"><%= otherUser.username %></h1>
            <p class="text-xs text-gray-500" id="typing-indicator"></p>
          </div>
        </div>
        <div class="flex space-x-2">
          <button onclick="startAudioCall()" class="p-3 rounded-xl bg-gradient-to-r from-green-500 to-green-600 hover:from-green-600 hover:to-green-700 text-white transition-all duration-200 transform hover:scale-105 active:scale-95 shadow-lg hover:shadow-xl" title="Audio Call">
            <svg class="h-5 w-5" fill="currentColor" viewBox="0 0 20 20">
              <path d="M2 3a1 1 0 011-1h2.153a1 1 0 01.986.836l.74 4.435a1 1 0 01-.54 1.06l-1.548.773a11.037 11.037 0 006.105 6.105l.774-1.548a1 1 0 011.059-.54l4.435.74a1 1 0 01.836.986V17a1 1 0 01-1 1h-2C7.82 18 2 12.18 2 5V3z"></path>
            </svg>
          </button>
          <button onclick="startVideoCall()" class="p-3 rounded-xl bg-gradient-to-r from-primary-500 to-primary-600 hover:from-primary-600 hover:to-primary-700 text-white transition-all duration-200 transform hover:scale-105 active:scale-95 shadow-lg hover:shadow-xl" title="Video Call">
            <svg class="h-5 w-5" fill="currentColor" viewBox="0 0 20 20">
              <path d="M2 6a2 2 0 012-2h6a2 2 0 012 2v6a2 2 0 01-2 2H4a2 2 0 01-2-2V6zM14.553 7.106A1 1 0 0014 8v4a1 1 0 00.553.894l2 1A1 1 0 0018 13V7a1 1 0 00-1.447-.894l-2 1z"></path>
            </svg>
          </button>
        </div>
      </div>
    </header>

    <!-- Messages Container -->
    <main class="flex-1 overflow-y-auto p-4 space-y-4 chat-messages pb-24" id="messages-container">
      <!-- Typing Indicator -->
      <div id="typing-indicator-container" class="hidden flex justify-start">
        <div class="bg-white/80 backdrop-blur-lg px-4 py-2 rounded-2xl rounded-bl-md border border-white/20 shadow-lg">
          <div class="flex items-center space-x-2">
            <div class="flex space-x-1">
              <div class="w-2 h-2 bg-secondary-400 rounded-full animate-bounce"></div>
              <div class="w-2 h-2 bg-secondary-400 rounded-full animate-bounce" style="animation-delay: 0.1s"></div>
              <div class="w-2 h-2 bg-secondary-400 rounded-full animate-bounce" style="animation-delay: 0.2s"></div>
            </div>
            <span class="text-xs text-secondary-500" id="typing-text">Typing...</span>
          </div>
        </div>
      </div>

      <% chats.forEach(chat => { %>
        <% const isOwn = chat.from.toString() === currentUser._id.toString(); %>
        <% const ext = chat.media ? chat.media.split('.').pop().toLowerCase() : ''; %>
        <% const isImage = ['jpg', 'jpeg', 'png', 'gif', 'webp'].includes(ext); %>
        <% const isVideo = ['mp4', 'avi', 'mov', 'wmv', 'flv', 'mkv', 'webm'].includes(ext); %>
        <% const isAudio = ['mp3', 'wav', 'ogg', 'm4a', 'webm'].includes(ext) || (chat.originalName && chat.originalName.startsWith('voice_')) || (chat.media && chat.media.includes('voice_')); %>

        <div class="flex <%= isOwn ? 'justify-end' : 'justify-start' %>">
          <% if (isAudio && chat.media) { %>
            <!-- Voice message container -->
            <div class="max-w-xs lg:max-w-md">
              <div class="<%= isOwn ? 'bg-gradient-to-r from-primary-500 to-primary-600' : 'bg-gradient-to-r from-indigo-500 to-purple-600' %> rounded-2xl <%= isOwn ? 'rounded-br-md' : 'rounded-bl-md' %> p-3 shadow-lg relative group">
                <div class="flex items-center space-x-3">
                  <button class="voice-play-btn flex-shrink-0 bg-white bg-opacity-20 border-2 border-white border-opacity-30 rounded-full w-10 h-10 flex items-center justify-center hover:bg-opacity-30 transition-all duration-200" data-audio-src="<%= chat.media.startsWith('/') ? chat.media : '/' + chat.media %>">
                    <svg class="play-icon w-5 h-5 text-white ml-0.5" fill="currentColor" viewBox="0 0 20 20">
                      <path d="M8 5v10l7-5-7-5z"/>
                    </svg>
                    <svg class="pause-icon w-5 h-5 text-white hidden" fill="currentColor" viewBox="0 0 20 20">
                      <path fill-rule="evenodd" d="M6 4a1 1 0 011 1v10a1 1 0 11-2 0V5a1 1 0 011-1zM13 4a1 1 0 011 1v10a1 1 0 11-2 0V5a1 1 0 011-1z" clip-rule="evenodd"/>
                    </svg>
                  </button>
                  <div class="flex-1 min-w-0">
                    <div class="voice-progress-bar-container h-1 bg-white bg-opacity-30 rounded-full cursor-pointer">
                      <div class="voice-progress h-full bg-white rounded-full transition-all duration-100" style="width: 0%"></div>
                    </div>
                  </div>
                  <div class="voice-duration text-white text-sm font-medium min-w-10 text-right">0:00</div>
                </div>
                <button onclick="summarizeContent('<%= chat._id %>', 'audio', '<%= chat.media %>')"
                        class="absolute -top-1 -right-1 opacity-0 group-hover:opacity-100 transition-opacity bg-white bg-opacity-20 text-white text-xs p-1.5 rounded-full hover:bg-opacity-30 shadow-lg">
                  <svg class="w-3 h-3" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
                  </svg>
                </button>
              </div>
              <div class="flex items-center justify-between mt-1 px-2">
                <span class="text-xs <%= isOwn ? 'text-secondary-500' : 'text-secondary-500' %>">
                  <%= new Date(chat.created_at).toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit' }) %>
                </span>
                <% if (chat.moderationResult && chat.moderationResult.flagged) { %>
                  <span class="text-xs text-red-400" title="Message was moderated">‚ö†Ô∏è</span>
                <% } %>
              </div>
            </div>
          <% } else { %>
            <div class="max-w-xs lg:max-w-md px-4 py-3 rounded-2xl
                        <%= isOwn ? 'bg-gradient-to-r from-primary-500 to-primary-600 text-white rounded-br-md' : 'bg-white/80 backdrop-blur-lg text-secondary-900 rounded-bl-md border border-white/20' %> shadow-lg">
          <% } %>

            <% if (chat.media && !isAudio) { %>
              <% 
              // Check if media was flagged by moderation
              const isMediaFlagged = chat.moderationResult && chat.moderationResult.flagged && chat.moderationResult.categories && 
                                   (chat.moderationResult.categories.includes('sexual') || 
                                    chat.moderationResult.categories.includes('violence') || 
                                    chat.moderationResult.categories.includes('harassment'));
              %>

              <% if (isMediaFlagged) { %>
                <!-- Show moderation message for flagged media -->
                <div class="mb-2 p-3 bg-yellow-50 border border-yellow-200 rounded-md">
                  <div class="flex items-center space-x-2">
                    <svg class="w-5 h-5 text-yellow-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-2.5L13.732 4c-.77-.833-1.732-.833-2.5 0L3.732 16.5c-.77.833.192 2.5 1.732 2.5z"></path>
                    </svg>
                    <span class="text-sm text-yellow-800">Media content was automatically removed due to policy violations.</span>
                  </div>
                </div>
              <% } else if (isImage) { %>
                <div class="mb-2">
                  <img src="<%= chat.media.startsWith('/') ? chat.media : '/' + chat.media %>"
                       alt="Media"
                       class="rounded-md max-h-60 shadow cursor-pointer hover:opacity-90 transition-opacity"
                       onclick="openMediaPreview(this.src, 'image', '<%= (chat.originalName || chat.media.split('/').pop()).replace(/'/g, '&apos;') %>')"
                       onerror="this.parentElement.innerHTML='<div class=&quot;p-3 bg-red-50 border border-red-200 rounded-md text-sm text-red-600&quot;>Failed to load image</div>'">
                </div>
              <% } else if (isVideo) { %>
                <div class="mb-2 relative group">
                  <div class="relative cursor-pointer"
                       onclick="openMediaPreview('<%= chat.media.startsWith('/') ? chat.media : '/' + chat.media %>', 'video', '<%= (chat.originalName || chat.media.split('/').pop()).replace(/'/g, '&apos;') %>')">
                    <video class="rounded-md max-h-60 shadow w-full" style="max-width: 100%;" preload="metadata"
                           onerror="this.parentElement.parentElement.innerHTML='<div class=&quot;p-3 bg-red-50 border border-red-200 rounded-md text-sm text-red-600&quot;>Failed to load video</div>'">
                      <source src="<%= chat.media.startsWith('/') ? chat.media : '/' + chat.media %>" type="video/<%= ext %>">
                      Your browser does not support the video tag.
                    </video>
                    <div class="absolute inset-0 flex items-center justify-center bg-black bg-opacity-30 opacity-0 group-hover:opacity-100 transition-opacity rounded-md">
                      <div class="bg-white bg-opacity-80 rounded-full p-3">
                        <svg class="h-8 w-8 text-primary-600" fill="currentColor" viewBox="0 0 24 24">
                          <path d="M8 5v14l11-7z"/>
                        </svg>
                      </div>
                    </div>
                  </div>
                  <button onclick="summarizeContent('<%= chat._id %>', 'video', '<%= chat.media %>'); event.stopPropagation();"
                          class="absolute top-2 right-2 opacity-0 group-hover:opacity-100 transition-all duration-200 bg-blue-500 hover:bg-blue-600 text-white text-xs px-2 py-1 rounded-full shadow-lg transform hover:scale-105"
                          title="Summarize video">
                    <svg class="w-3 h-3 inline mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
                    </svg>
                    Summarize
                  </button>
                </div>
              <% } else { %>
                <% const extColor = ext === 'pdf' ? 'text-red-500' :
                    ['doc','docx'].includes(ext) ? 'text-blue-600' :
                    ['xls','xlsx'].includes(ext) ? 'text-green-600' :
                    ['ppt','pptx'].includes(ext) ? 'text-orange-500' :
                    ['zip','rar'].includes(ext) ? 'text-yellow-500' : 'text-gray-600';
                %>
                <div class="bg-gray-100 rounded-md p-3 mb-2 shadow flex flex-col space-y-2">
                  <div class="flex items-center space-x-3">
                    <svg class="w-6 h-6 <%= extColor %>" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24">
                      <path d="M12 2H6a2 2 0 00-2 2v16a2 2 0 002 2h12a2 2 0 002-2V8z"/>
                      <polyline points="12 2 12 8 18 8"/>
                    </svg>
                    <div>
                      <p class="font-semibold text-gray-800 text-sm truncate max-w-xs">
                        <%= chat.originalName || chat.media.split('/').pop() %>
                      </p>
                      <p class="text-xs text-gray-500 uppercase">DOCUMENT</p>
                    </div>
                  </div>
                  <div class="flex space-x-3 mt-1">
                    <a href="<%= chat.media.startsWith('/') ? chat.media : '/' + chat.media %>" target="_blank"
                       class="text-xs px-3 py-1 bg-blue-500 text-white rounded hover:bg-blue-600">Open</a>
                    <a href="<%= chat.media.startsWith('/') ? chat.media : '/' + chat.media %>" download="<%= chat.originalName || chat.media.split('/').pop() %>"
                       class="text-xs px-3 py-1 bg-green-500 text-white rounded hover:bg-green-600">Download</a>
                  </div>
                </div>
              <% } %>
            <% } %>

            <% if (chat.msg && !isAudio) { %>
              <div class="relative group">
                <p class="text-sm leading-relaxed"><%= chat.msg %></p>
                <% 
                const hasVideoLink = /(?:https?:\/\/(?:www\.)?(?:youtube\.com\/watch\?v=|youtu\.be\/|vimeo\.com\/video\/|dailymotion\.com\/video\/))/.test(chat.msg);
                const shouldShowSummarizeBtn = chat.msg.length > 200 || hasVideoLink;
                %>
                <% if (shouldShowSummarizeBtn) { %>
                  <button onclick="summarizeContent('<%= chat._id %>', '<%= hasVideoLink ? 'video_link' : 'text' %>', `<%= chat.msg.replace(/'/g, "\\'").replace(/`/g, "\\`").replace(/\n/g, "\\n") %>`)"
                          class="absolute -top-1 -right-1 opacity-0 group-hover:opacity-100 transition-all duration-200 bg-blue-500 hover:bg-blue-600 text-white text-xs px-2 py-1 rounded-full shadow-lg transform hover:scale-105"
                          title="Summarize content">
                    <% if (hasVideoLink) { %>
                      <svg class="w-3 h-3 inline mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"></path>
                      </svg>
                      Analyze Video
                    <% } else { %>
                      <svg class="w-3 h-3 inline mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path>
                      </svg>
                      Summarize
                    <% } %>
                  </button>
                <% } %>
              </div>
            <% } %>

            <% if (!isAudio) { %>
              <div class="flex items-center justify-between mt-2">
                <span class="text-xs <%= isOwn ? 'text-primary-100' : 'text-secondary-500' %>">
                  <%= new Date(chat.created_at).toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit' }) %>
                </span>
                <% if (chat.moderationResult && chat.moderationResult.flagged) { %>
                  <span class="text-xs text-red-400" title="Message was moderated">‚ö†Ô∏è</span>
                <% } %>
              </div>
            </div>
          <% } %>
        </div>
      <% }); %>
    </main>

    <!-- AI Summary Modal -->
    <div id="ai-summary-modal" class="hidden fixed inset-0 bg-black bg-opacity-50 z-50 flex items-center justify-center" onclick="closeAISummaryOnOutsideClick(event)">
      <div class="bg-white rounded-2xl p-6 mx-4 max-w-md w-full max-h-96 overflow-y-auto relative">
        <div class="flex justify-between items-center mb-4">
          <h3 class="text-lg font-semibold text-gray-900">ü§ñ AI Summary</h3>
          <button onclick="closeAISummary()" class="text-gray-400 hover:text-red-600 hover:bg-red-50 rounded-full p-1 transition-colors duration-200">
            <svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
            </svg>
          </button>
        </div>
        <div id="ai-summary-content" class="text-sm text-gray-700 leading-relaxed mb-4">
          <!-- Summary content will be inserted here -->
        </div>
        <div id="ai-summary-loading" class="text-center py-4">
          <div class="animate-spin rounded-full h-8 w-8 border-b-2 border-primary-600 mx-auto"></div>
          <p class="text-sm text-gray-500 mt-2">Generating summary...</p>
        </div>
        <div class="flex justify-center mt-4 pt-4 border-t border-gray-200">
          <button onclick="closeAISummary()" class="px-6 py-2 bg-gray-100 hover:bg-gray-200 text-gray-700 rounded-lg transition-colors duration-200 font-medium">
            Close Summary
          </button>
        </div>
      </div>
    </div>

    <!-- Smart Replies Panel -->
    <div id="smart-replies-panel" class="hidden fixed bottom-24 left-0 right-0 z-50 mx-4 mb-2">
      <div class="bg-white/90 backdrop-blur-lg border border-secondary-200 rounded-xl shadow-lg p-3">
        <div class="flex items-center justify-between mb-2">
          <span class="text-xs font-medium text-gray-600">ü§ñ Smart Replies</span>
          <button onclick="hideSmartReplies()" class="text-gray-400 hover:text-gray-600">
            <svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
            </svg>
          </button>
        </div>
        <div id="smart-replies-content" class="space-y-2">
          <!-- Smart reply buttons will be inserted here -->
        </div>
      </div>
    </div>

    <!-- Media Preview (positioned above the footer) -->
    <div id="filePreview" class="hidden fixed bottom-24 left-0 right-0 z-50 mx-4 mb-2">
      <div class="flex items-center justify-between p-3 bg-white/90 backdrop-blur-lg border border-secondary-200 rounded-xl shadow-lg">
        <div id="previewContent" class="flex items-center space-x-3 flex-1 overflow-hidden"></div>
        <button id="removeFile" type="button" class="ml-3 p-2 rounded-full hover:bg-secondary-100 text-secondary-500 hover:text-red-500 transition-colors flex-shrink-0">
          <svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
          </svg>
        </button>
      </div>
    </div>

    <!-- Voice Recording Modal -->
    <div id="voice-recording-modal" class="hidden fixed inset-0 bg-black bg-opacity-50 z-50 flex items-center justify-center">
      <div class="bg-white rounded-2xl p-6 mx-4 max-w-sm w-full">
        <div class="text-center">
          <div class="mb-4">
            <div class="w-20 h-20 bg-red-500 rounded-full mx-auto flex items-center justify-center animate-pulse">
              <svg class="h-10 w-10 text-white" fill="currentColor" viewBox="0 0 20 20">
                <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
              </svg>
            </div>
          </div>
          <h3 class="text-lg font-semibold text-gray-900 mb-2">Recording Voice Message</h3>
          <p class="text-sm text-gray-500 mb-4">Tap to stop recording</p>
          <div class="flex space-x-3 justify-center">
            <button onclick="stopVoiceRecording()" class="bg-red-500 text-white px-6 py-2 rounded-lg hover:bg-red-600 transition-colors">
              Stop & Send
            </button>
            <button onclick="cancelVoiceRecording()" class="bg-gray-500 text-white px-6 py-2 rounded-lg hover:bg-gray-600 transition-colors">
              Cancel
            </button>
          </div>
        </div>
      </div>
    </div>

    <!-- Call Interface -->
    <div id="call-interface" class="hidden fixed inset-0 bg-gray-900 z-[100] flex flex-col">
      <!-- Call content will be inserted here -->
    </div>

    <!-- Incoming Call Notification -->
    <div id="incoming-call-notification" class="hidden fixed inset-0 bg-gray-900 bg-opacity-95 z-[100] flex items-center justify-center">
      <!-- Call notification content will be inserted here -->
    </div>

    <!-- Message Input -->
    <footer id="message-footer" class="fixed bottom-0 left-0 right-0 bg-white/90 backdrop-blur-lg border-t border-secondary-200" style="z-index: 1000;">
      <div class="p-4">
        <form id="message-form" enctype="multipart/form-data" class="flex items-center space-x-3">
          <input type="file" id="media-input" name="media" class="hidden" accept="image/*,video/*,audio/*,.pdf,.doc,.docx,.xls,.xlsx,.ppt,.pptx,.zip,.rar">
          <label for="media-input" class="cursor-pointer p-3 rounded-xl bg-secondary-100 hover:bg-secondary-200 transition">
            <svg class="h-5 w-5 text-secondary-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.172 7l-6.586 6.586a2 2 0 102.828 2.828l6.414-6.586a4 4 0 00-5.656-5.656l-6.415 6.585a6 6 0 108.486 8.486L20.5 13"></path>
            </svg>
          </label>

          <!-- Voice Message Button -->
          <button type="button" id="voice-message-btn" onclick="startVoiceRecording()" class="cursor-pointer p-3 rounded-xl bg-secondary-100 hover:bg-secondary-200 transition">
            <svg class="h-5 w-5 text-secondary-600" fill="currentColor" viewBox="0 0 20 20">
              <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
            </svg>
          </button>

          <!-- AI Reply Button -->
          <button type="button" id="ai-reply-btn" onclick="generateAIResponse()" class="cursor-pointer p-3 rounded-xl bg-blue-100 hover:bg-blue-200 transition" title="Generate AI Reply">
            <svg class="h-5 w-5 text-blue-600" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path>
            </svg>
          </button>

          <div class="flex-1 relative">
            <textarea name="msg" id="message-input" placeholder="Type your message..."
                   class="w-full px-4 py-3 bg-secondary-50 border border-secondary-200 rounded-2xl focus:ring-2 focus:ring-primary-500 focus:border-transparent transition-all duration-200 pr-12 resize-none"
                   autocomplete="off" rows="1" style="min-height: 48px; overflow-y: hidden;"></textarea>
          </div>

          <button type="submit" class="inline-flex items-center justify-center w-12 h-12 bg-gradient-to-r from-primary-500 to-primary-600 hover:from-primary-600 hover:to-primary-700 text-white rounded-2xl focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary-500 transition-all duration-200 transform hover:scale-105 active:scale-95 shadow-lg hover:shadow-xl">
            <svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 19l9 2-9-18-9 18 9-2zm0 0v-8"></path>
            </svg>
          </button>
        </form>
      </div>
    </footer>
  </div>

  <!-- Full-Screen Media Preview Modal -->
  <div id="mediaPreviewModal" class="hidden fixed inset-0 bg-black bg-opacity-90 z-50 flex items-center justify-center">
    <div class="relative max-w-screen-lg max-h-screen-lg w-full h-full flex items-center justify-center p-4">
      <!-- Close Button -->
      <button onclick="closeMediaPreview()"
              class="absolute top-4 right-4 z-60 bg-black bg-opacity-50 text-white p-2 rounded-full hover:bg-opacity-70 transition-colors">
        <svg class="h-6 w-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
        </svg>
      </button>

      <!-- Media Content Container -->
      <div id="previewMediaContainer" class="flex items-center justify-center w-full h-full">
        <!-- Content will be dynamically inserted here -->
      </div>

      <!-- Download Button -->
      <button id="downloadMediaBtn" onclick="downloadMedia()"
              class="absolute bottom-4 right-4 z-60 bg-primary-500 hover:bg-primary-600 text-white px-4 py-2 rounded-lg transition-colors flex items-center space-x-2">
        <svg class="h-5 w-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 10v6m0 0l-3-3m3 3l3-3M3 17V7a2 2 0 012-2h6l2 2h6a2 2 0 012 2v10a2 2 0 01-2 2H5a2 2 0 01-2-2z"></path>
        </svg>
        <span>Download</span>
      </button>
    </div>
  </div>

  <script src="/socket.io/socket.io.js"></script>
  <script src="/js/notifications.js"></script>
  <script src="/js/webrtc-debug.js"></script>
  <script src="/js/main.js"></script>
  <script src="/js/call.js"></script>
  <script>
    // Global variables
    const otherUserId = "<%= otherUser._id %>";
    const currentUserId = "<%= currentUser._id %>";

    // Initialize socket and call system
    let chatSocket = null;
    let callManager = null;

    // Call-related variables
    let localStream = null;
    let remoteStream = null;
    let peerConnection = null;
    let currentCall = null;
    let isInCall = false;
    let callType = null;

    // Enhanced WebRTC configuration with reliable STUN/TURN servers for Replit
    const pcConfig = {
      iceServers: [
        { urls: 'stun:stun.l.google.com:19302' },
        { urls: 'stun:stun1.l.google.com:19302' },
        { urls: 'stun:stun2.l.google.com:19302' },
        {
          urls: 'turn:openrelay.metered.ca:80',
          username: 'openrelayproject',
          credential: 'openrelayproject'
        },
        {
          urls: 'turn:openrelay.metered.ca:443',
          username: 'openrelayproject',
          credential: 'openrelayproject'
        },
        {
          urls: 'turn:openrelay.metered.ca:443?transport=tcp',
          username: 'openrelayproject',
          credential: 'openrelayproject'
        }
      ],
      iceCandidatePoolSize: 10
    };

    // Initialize everything when DOM is ready
    document.addEventListener('DOMContentLoaded', function() {
      console.log('Initializing chat page...');

      // Create socket connection
      chatSocket = io();
      chatSocket.emit('userOnline', currentUserId);

      // Initialize notification manager
      if (window.notificationManager) {
        window.notificationManager.setSocket(chatSocket, currentUserId);
      }

      initializeCallSystem();
      initializeChat();
      initializeScrollBehavior();

      console.log('Chat page initialization complete');
    });

    function initializeCallSystem() {
      console.log('Initializing call system...');

      // Socket event listeners for calls
      chatSocket.on('incoming-call', (data) => {
        console.log('üìû Incoming call received:', data);
        showIncomingCallNotification(data);
      });

      chatSocket.on('call-accepted', (data) => {
        console.log('üìû Call accepted:', data);
        handleCallAccepted(data);
      });

      chatSocket.on('call-declined', (data) => {
        console.log('üìû Call declined:', data);
        handleCallDeclined(data);
      });

      chatSocket.on('call-ended', (data) => {
        console.log('üìû Call ended:', data);
        endCall();
      });

      chatSocket.on('call-cancelled', (data) => {
        console.log('üìû Call cancelled:', data);
        hideCallNotification();
      });

      chatSocket.on('call-timeout', (data) => {
        console.log('üìû Call timeout:', data);
        handleCallTimeout();
      });

      chatSocket.on('call-missed', (data) => {
        console.log('üìû Call missed:', data);
        showMissedCallNotification(data);
      });

      // WebRTC signaling events
      chatSocket.on('call-offer', async (data) => {
        console.log('üì• Received call offer:', data);
        await handleCallOffer(data);
      });

      chatSocket.on('call-answer', async (data) => {
        console.log('üì• Received call answer:', data);
        await handleCallAnswer(data);
      });

      chatSocket.on('ice-candidate', async (data) => {
        console.log('üì• Received ICE candidate:', data);
        await handleIceCandidate(data);
      });

      console.log('Call system initialized');
    }

    function initializeChat() {
      // Room for private chat
      const roomId = [currentUserId, otherUserId].sort().join('_');
      chatSocket.emit('joinRoom', roomId);

      // Initialize message form
      const messageForm = document.getElementById('message-form');
      if (messageForm) {
        messageForm.addEventListener('submit', sendMessage);
      }

      // Initialize typing indicators
      const messageInput = document.getElementById('message-input');
      if (messageInput) {
        let typingTimer;
        messageInput.addEventListener('input', () => {
          chatSocket.emit('typing start', {
            from: currentUserId,
            to: otherUserId,
            username: '<%= currentUser.username %>'
          });

          clearTimeout(typingTimer);
          typingTimer = setTimeout(() => {
            chatSocket.emit('typing stop', {
              from: currentUserId,
              to: otherUserId,
              username: '<%= currentUser.username %>'
            });
          }, 1000);
        });
      }

      // Listen for incoming messages
      chatSocket.on('chat message', (message) => {
        appendMessage(message);
      });

      // Listen for voice messages in real-time
      chatSocket.on('voiceMessage', (data) => {
        console.log('‚úÖ Voice message received via Socket.IO');
        appendVoiceMessage(data);
      });

      // Listen for typing indicators
      chatSocket.on('user typing', (data) => {
        showTypingIndicator(data);
      });
    }

    // Call initiation functions
    function startAudioCall() {
      console.log('Starting audio call to user:', otherUserId);
      initiateCall(otherUserId, 'audio');
    }

    function startVideoCall() {
      console.log('Starting video call to user:', otherUserId);
      initiateCall(otherUserId, 'video');
    }

    async function initiateCall(receiverId, type) {
      console.log(`Initiating ${type} call to user ${receiverId}`);

      try {
        const response = await fetch('/call/initiate', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ receiverId, type })
        });

        const result = await response.json();
        console.log('Call initiate response:', result);

        if (result.success) {
          currentCall = {
            callId: result.callId,
            receiverId: receiverId,
            type: type,
            role: 'caller'
          };
          callType = type;

          await getUserMedia(type);
          showCallingInterface(receiverId, type);

          console.log('Call initiated successfully, showing UI');
        } else {
          alert(result.error || 'Failed to initiate call');
        }
      } catch (error) {
        console.error('Error initiating call:', error);
        alert('Failed to start call');
      }
    }

    async function getUserMedia(type) {
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100,
          channelCount: 1
        },
        video: type === 'video' ? {
          width: { ideal: 640, min: 320 },
          height: { ideal: 480, min: 240 },
          frameRate: { ideal: 30, min: 15 }
        } : false
      };

      try {
        console.log('üé§ Getting user media with constraints:', constraints);

        // Clean up existing stream
        if (localStream) {
          console.log('üé§ Stopping existing local stream...');
          localStream.getTracks().forEach(track => {
            track.stop();
            console.log(`üé§ Stopped ${track.kind} track`);
          });
          localStream = null;
        }

        // Request media with proper error handling
        localStream = await navigator.mediaDevices.getUserMedia(constraints);
        
        if (!localStream || !localStream.active) {
          throw new Error('Failed to get valid media stream');
        }

        console.log('‚úÖ User media obtained successfully');
        console.log('üé§ Total tracks:', localStream.getTracks().length);
        console.log('üé§ Audio tracks:', localStream.getAudioTracks().length);
        console.log('üìπ Video tracks:', localStream.getVideoTracks().length);

        // Verify audio tracks
        const audioTracks = localStream.getAudioTracks();
        if (audioTracks.length === 0) {
          throw new Error('No audio tracks available - microphone access failed');
        }

        // Ensure audio tracks are enabled and live
        audioTracks.forEach((track, index) => {
          track.enabled = true;
          console.log(`üîä Audio track ${index}: ${track.label} - enabled: ${track.enabled}, state: ${track.readyState}`);
          
          if (track.readyState !== 'live') {
            console.warn(`‚ö†Ô∏è Audio track ${index} is not live:`, track.readyState);
          }
        });

        return localStream;
      } catch (error) {
        console.error('‚ùå Error getting user media:', error);
        
        let errorMessage = 'Failed to access microphone';
        if (error.name === 'NotAllowedError') {
          errorMessage = 'Microphone access denied. Please allow microphone permissions and try again.';
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'No microphone found. Please connect a microphone and try again.';
        } else if (error.name === 'NotReadableError') {
          errorMessage = 'Microphone is being used by another application.';
        }

        alert(errorMessage);
        throw error;
      }
    }

    function testAudioCapabilities(stream) {
      try {
        // Test Web Audio API support
        const AudioContextClass = window.AudioContext || window.webkitAudioContext;
        if (!AudioContextClass) {
          console.warn('‚ö†Ô∏è Web Audio API not supported');
          return;
        }

        const audioContext = new AudioContextClass();
        console.log('üîä Audio context state:', audioContext.state);

        // Resume audio context if suspended
        if (audioContext.state === 'suspended') {
          audioContext.resume().then(() => {
            console.log('üîä Audio context resumed');
          });
        }

        // Create analyzer for audio level detection
        const analyser = audioContext.createAnalyser();
        const microphone = audioContext.createMediaStreamSource(stream);
        const dataArray = new Uint8Array(analyser.frequencyBinCount);

        microphone.connect(analyser);
        analyser.fftSize = 256;

        let levelCheckCount = 0;
        const maxChecks = 50; // Check for 5 seconds max

        function checkAudioLevel() {
          if (levelCheckCount >= maxChecks) {
            console.log('üîä Audio level test completed');
            cleanupAudioTest();
            return;
          }

          analyser.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b) / dataArray.length;

          if (average > 5) { // Lower threshold
            console.log('‚úÖ Audio input detected, level:', average);
            cleanupAudioTest();
            return;
          }

          levelCheckCount++;
          requestAnimationFrame(checkAudioLevel);
        }

        function cleanupAudioTest() {
          try {
            microphone.disconnect();
            audioContext.close();
          } catch (e) {
            console.log('üîä Audio test cleanup completed');
          }
        }

        // Start level check
        checkAudioLevel();

      } catch (error) {
        console.warn('‚ö†Ô∏è Audio capabilities test failed:', error.message);
      }
    }

    function showCallingInterface(receiverId, type) {
      console.log(`Showing calling interface for ${type} call`);

      hideCallInterface();

      // ‚úÖ FIX: Hide chat typing bar during call
      const messageFooter = document.getElementById('message-footer');
      if (messageFooter) {
        messageFooter.style.display = 'none';
        console.log('‚úÖ Chat typing bar hidden during calling');
      }

      const callInterface = document.getElementById('call-interface');
      callInterface.className = 'fixed inset-0 bg-gray-900 z-[100] flex flex-col items-center justify-center';

      callInterface.innerHTML = `
        <div class="text-center text-white">
          <div class="mb-8">
            <div class="w-32 h-32 bg-gray-700 rounded-full mx-auto mb-4 flex items-center justify-center">
              <svg class="w-16 h-16" fill="currentColor" viewBox="0 0 20 20">
                <path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-6-3a2 2 0 11-4 0 2 2 0 014 0zm-2 4a5 5 0 00-4.546 2.916A5.986 5.986 0 0010 16a5.986 5.986 0 004.546-2.084A5 5 0 0010 11z" clip-rule="evenodd"></path>
              </svg>
            </div>
            <h2 class="text-2xl font-semibold mb-2">Calling...</h2>
            <p class="text-gray-300">${type === 'video' ? 'Video' : 'Audio'} Call</p>
          </div>

          <div class="flex justify-center space-x-6">
            <button onclick="cancelCall()" 
                    class="bg-red-500 hover:bg-red-600 text-white p-4 rounded-full transition-colors">
              <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                <path d="M2 3a1 1 0 011-1h2.153a1 1 0 01.986.836l.74 4.435a1 1 0 01-.54 1.06l-1.548.773a11.037 11.037 0 006.105 6.105l.774-1.548a1 1 0 011.059-.54l4.435.74a1 1 0 01.836.986V17a1 1 0 01-1 1h-2C7.82 18 2 12.18 2 5V3z"></path>
              </svg>
            </button>
          </div>
        </div>

        <div id="local-video-container" class="absolute bottom-4 right-4" style="display: ${type === 'video' ? 'block' : 'none'}">
          <video id="local-video" autoplay muted class="w-48 h-36 bg-gray-800 rounded-lg"></video>
        </div>

        <div id="remote-video-container" class="absolute inset-0 flex items-center justify-center" style="display: none;">
          <video id="remote-video" autoplay class="max-w-full max-h-full"></video>
        </div>
      `;

      callInterface.classList.remove('hidden');

      if (localStream && type === 'video') {
        const localVideo = document.getElementById('local-video');
        if (localVideo) {
          localVideo.srcObject = localStream;
        }
      }
    }

    function showIncomingCallNotification(data) {
      console.log('Showing incoming call notification');

      hideCallNotification();

      const notification = document.getElementById('incoming-call-notification');
      notification.innerHTML = `
        <div class="bg-white rounded-lg p-8 text-center max-w-md mx-4">
          <div class="mb-6">
            <img src="${data.caller.avatar || '/icons/user-default.png'}" alt="${data.caller.username}" 
                 class="w-20 h-20 rounded-full mx-auto mb-4">
            <h3 class="text-xl font-semibold mb-2">${data.caller.username}</h3>
            <p class="text-gray-600">Incoming ${data.type} call</p>
          </div>

          <div class="flex justify-center space-x-6">
            <button onclick="acceptCall('${data.callId}', '${data.type}')" 
                    class="bg-green-500 hover:bg-green-600 text-white p-4 rounded-full transition-colors">
              <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                <path d="M2 3a1 1 0 011-1h2.153a1 1 0 01.986.836l.74 4.435a1 1 0 01-.54 1.06l-1.548.773a11.037 11.037 0 006.105 6.105l.774-1.548a1 1 0 011.059-.54l4.435.74a1 1 0 01.836.986V17a1 1 0 01-1 1h-2C7.82 18 2 12.18 2 5V3z"></path>
              </svg>
            </button>
            <button onclick="declineCall('${data.callId}')" 
                    class="bg-red-500 hover:bg-red-600 text-white p-4 rounded-full transition-colors">
              <svg class="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                <path d="M2 3a1 1 0 011-1h2.153a1 1 0 01.986.836l.74 4.435a1 1 0 01-.54 1.06l-1.548.773a11.037 11.037 0 006.105 6.105l.774-1.548a1 1 0 011.059-.54l4.435.74a1 1 0 01.836.986V17a1 1 0 01-1 1h-2C7.82 18 2 12.18 2 5V3z"></path>
              </svg>
            </button>
          </div>
        </div>
      `;

      notification.classList.remove('hidden');
    }

    async function acceptCall(callId, type) {
      console.log(`üü¢ Accepting ${type} call ${callId}`);

      try {
        // Set call state immediately
        currentCall = {
          callId: callId,
          type: type,
          role: 'receiver'
        };
        callType = type;

        // Get user media first
        console.log('üé§ Getting user media...');
        await getUserMedia(type);
        console.log('‚úÖ User media obtained');

        // Update UI
        hideCallNotification();
        showActiveCallInterface(type);

        // üîä AUTOPLAY FIX: Trigger audio playback on user gesture (accept)
        // This ensures browser allows audio autoplay
        console.log('üîä Preparing audio autoplay after user gesture...');

        // Create peer connection
        console.log('üîó Creating peer connection...');
        await createPeerConnection();

        // Respond to server that call is accepted
        const response = await fetch(`/call/${callId}/respond`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ action: 'accept' })
        });

        if (response.ok) {
          console.log('‚úÖ Call accepted on server, waiting for offer...');
        } else {
          throw new Error('Failed to accept call on server');
        }

      } catch (error) {
        console.error('‚ùå Error accepting call:', error);
        alert('Failed to accept call: ' + error.message);
        endCall();
      }
    }

    async function declineCall(callId) {
      console.log(`Declining call ${callId}`);

      try {
        await fetch(`/call/${callId}/respond`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ action: 'decline' })
        });

        hideCallNotification();
      } catch (error) {
        console.error('Error declining call:', error);
      }
    }

    async function cancelCall() {
      console.log('Cancelling call');

      if (currentCall) {
        try {
          await fetch(`/call/${currentCall.callId}/cancel`, {
            method: 'POST'
          });
        } catch (error) {
          console.error('Error cancelling call:', error);
        }
      }

      endCall();
    }

    let callStartTime = null;
    let callDurationTimer = null;

    function startCallTimer() {
      if (callDurationTimer) return; // Already started

      callStartTime = Date.now();
      callDurationTimer = setInterval(() => {
        const elapsed = Date.now() - callStartTime;
        const minutes = Math.floor(elapsed / 60000);
        const seconds = Math.floor((elapsed % 60000) / 1000);
        const durationElement = document.getElementById('call-duration');
        if (durationElement) {
          durationElement.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
        }

        // Monitor audio flow every 5 seconds
        if (elapsed % 5000 < 1000) {
          monitorAudioFlow();
        }
      }, 1000);
    }

    function monitorAudioFlow() {
      if (!peerConnection) return;

      // Check if we have active audio tracks
      const senders = peerConnection.getSenders();
      const receivers = peerConnection.getReceivers();

      console.log('üîä Audio monitoring:');
      console.log('üì§ Outgoing tracks:', senders.filter(s => s.track && s.track.kind === 'audio').map(s => ({
        enabled: s.track.enabled,
        muted: s.track.muted,
        readyState: s.track.readyState
      })));

      console.log('üì• Incoming tracks:', receivers.filter(r => r.track && r.track.kind === 'audio').map(r => ({
        enabled: r.track.enabled,
        muted: r.track.muted,
        readyState: r.track.readyState
      })));

      // Check remote audio element
      const remoteAudio = document.getElementById('remote-audio');
      if (remoteAudio) {
        console.log('üîä Remote audio element:', {
          paused: remoteAudio.paused,
          muted: remoteAudio.muted,
          volume: remoteAudio.volume,
          readyState: remoteAudio.readyState,
          currentTime: remoteAudio.currentTime,
          hasSource: !!remoteAudio.srcObject
        });

        // If audio is paused, try to resume it
        if (remoteAudio.paused && remoteAudio.srcObject) {
          console.log('üîä Attempting to resume paused remote audio...');
          remoteAudio.play().catch(err => {
            console.warn('‚ö†Ô∏è Could not resume remote audio:', err);
          });
        }
      } else {
        console.warn('‚ö†Ô∏è No remote audio element found');
      }

      // Get WebRTC stats for audio
      if (window.WebRTCDebugger) {
        WebRTCDebugger.logPeerConnectionStats(peerConnection);
      }
    }

    function stopCallTimer() {
      if (callDurationTimer) {
        clearInterval(callDurationTimer);
        callDurationTimer = null;
        callStartTime = null;
      }
    }

    async function endCall() {
      console.log('üìû Ending call...');

      stopCallTimer();

      if (currentCall) {
        try {
          console.log('üìû Notifying server of call end...');
          await fetch(`/call/${currentCall.callId}/end`, {
            method: 'POST'
          });

          // Notify the other peer
          chatSocket.emit('call-ended', { callId: currentCall.callId });

        } catch (error) {
          console.error('‚ùå Error ending call on server:', error);
        }
      }

      // Clean up media streams
      if (localStream) {
        console.log('üìû Stopping local stream tracks...');
        localStream.getTracks().forEach(track => {
          track.stop();
          console.log(`üìû Stopped ${track.kind} track`);
        });
        localStream = null;
      }

      // Clean up peer connection
      if (peerConnection) {
        console.log('üìû Closing peer connection...');
        peerConnection.close();
        peerConnection = null;
      }

      // Clean up remote audio element
      const remoteAudio = document.getElementById('remote-audio');
      if (remoteAudio) {
        remoteAudio.srcObject = null;
        remoteAudio.remove();
      }

      // Clear pending ICE candidates
      if (window.pendingIceCandidates) {
        window.pendingIceCandidates = [];
      }

      hideCallInterface();
      hideCallNotification();

      // ‚úÖ FIX: Show chat typing bar again after call ends
      const messageFooter = document.getElementById('message-footer');
      if (messageFooter) {
        messageFooter.style.display = 'block';
        console.log('‚úÖ Chat typing bar shown again after call end');
      }

      currentCall = null;
      isInCall = false;
      callType = null;

      console.log('‚úÖ Call ended and cleaned up');
    }

    function showActiveCallInterface(type) {
      console.log(`Showing active call interface for ${type} call`);

      hideCallInterface();

      // ‚úÖ FIX: Hide chat typing bar during call
      const messageFooter = document.getElementById('message-footer');
      if (messageFooter) {
        messageFooter.style.display = 'none';
        console.log('‚úÖ Chat typing bar hidden during call');
      }

      const callInterface = document.getElementById('call-interface');
      callInterface.className = 'fixed inset-0 bg-gray-900 z-[100] flex flex-col';

      callInterface.innerHTML = `
        <div class="flex-1 flex items-center justify-center bg-gray-800">
          <video id="remote-video" autoplay playsinline class="max-w-full max-h-full" style="display: ${type === 'video' ? 'block' : 'none'}"></video>
          <div id="audio-indicator" class="text-white text-center" style="display: ${type === 'audio' ? 'block' : 'none'}">
            <div class="mb-4">
              <div class="w-32 h-32 mx-auto mb-4 bg-gradient-to-br from-green-400 to-green-600 rounded-full flex items-center justify-center animate-pulse">
                <svg class="w-16 h-16 text-white" fill="currentColor" viewBox="0 0 20 20">
                  <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
                </svg>
              </div>
            </div>
            <p class="text-xl font-semibold">Audio Call</p>
            <p class="text-sm text-gray-300 mt-2">Connected</p>
            <div id="call-duration" class="text-lg font-mono mt-4">00:00</div>
          </div>
        </div>

        <div id="local-video-container" class="absolute bottom-20 right-4" style="display: ${type === 'video' ? 'block' : 'none'}">
          <video id="local-video" autoplay muted class="w-48 h-36 bg-gray-700 rounded-lg"></video>
        </div>

        <div class="bg-gray-800 p-6 flex justify-center space-x-4">
          <button id="toggle-audio" onclick="toggleAudio()" 
                  class="bg-gray-600 hover:bg-gray-700 text-white p-4 rounded-full transition-colors">
            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20">
              <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
            </svg>
          </button>

          <button id="test-audio" onclick="testAudioPlayback()" 
                  class="bg-blue-600 hover:bg-blue-700 text-white p-4 rounded-full transition-colors" title="Test Audio">
            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20">
              <path d="M10 12a2 2 0 100-4 2 2 0 000 4z"></path>
              <path fill-rule="evenodd" d="M.458 10C1.732 5.943 5.522 3 10 3s8.268 2.943 9.542 7c-1.274 4.057-5.064 7-9.542 7S1.732 14.057.458 10zM14 10a4 4 0 11-8 0 4 4 0 018 0z" clip-rule="evenodd"></path>
            </svg>
          </button>

          <button id="toggle-video" onclick="toggleVideo()" 
                  class="bg-gray-600 hover:bg-gray-700 text-white p-4 rounded-full transition-colors"
                  style="display: ${type === 'video' ? 'block' : 'none'}">
            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20">
              <path d="M2 6a2 2 0 012-2h6a2 2 0 012 2v6a2 2 0 01-2 2H4a2 2 0 01-2-2V6zM14.553 7.106A1 1 0 0014 8v4a1 1 0 00.553.894l2 1A1 1 0 0018 13V7a1 1 0 00-1.447-.894l-2 1z"></path>
            </svg>
          </button>

          <button onclick="endCall()" 
                  class="bg-red-500 hover:bg-red-600 text-white p-4 rounded-full transition-colors">
            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20">
              <path d="M2 3a1 1 0 011-1h2.153a1 1 0 01.986.836l.74 4.435a1 1 0 01-.54 1.06l-1.548.773a11.037 11.037 0 006.105 6.105l.774-1.548a1 1 0 011.059-.54l4.435.74a1 1 0 01.836.986V17a1 1 0 01-1 1h-2C7.82 18 2 12.18 2 5V3z"></path>
            </svg>
          </button>
        </div>
      `;

      callInterface.classList.remove('hidden');

      if (localStream) {
        const localVideo = document.getElementById('local-video');
        if (localVideo) {
          localVideo.srcObject = localStream;
        }
      }

      isInCall = true;
    }

    async function createPeerConnection() {
      console.log('üîó Creating peer connection with config:', pcConfig);

      // Close existing connection
      if (peerConnection) {
        peerConnection.close();
        console.log('üîó Closed existing peer connection');
      }

      // Clear any pending ICE candidates
      window.pendingIceCandidates = [];

      peerConnection = new RTCPeerConnection(pcConfig);

      // ‚úÖ FIX: Connection state monitoring with proper UI updates
      peerConnection.onconnectionstatechange = () => {
        console.log('üîó Connection state changed to:', peerConnection.connectionState);
        
        if (peerConnection.connectionState === 'connected') {
          console.log('‚úÖ PEER CONNECTION ESTABLISHED - AUDIO SHOULD FLOW!');
          
          // ‚úÖ KEY FIX: Update caller UI from "Calling..." to "Connected"
          if (currentCall && currentCall.role === 'caller') {
            console.log('üîÑ CALLER UI UPDATE: Switching from calling to connected state');
            showActiveCallInterface(callType);
          }
          
          // Update status indicators
          updateCallConnectionStatus('Connected - Audio Active', '#10b981');
          startCallTimer();
          
          // Verify audio after brief delay
          setTimeout(() => verifyAudioFlow(), 1000);
          
        } else if (peerConnection.connectionState === 'connecting') {
          console.log('üîÑ Peer connection connecting...');
          updateCallConnectionStatus('Connecting...', '#f59e0b');
        } else if (peerConnection.connectionState === 'failed') {
          console.error('‚ùå Peer connection failed');
          alert('Call connection failed. Please check your network and try again.');
          endCall();
        }
      };

      // ‚úÖ FIX: Enhanced ICE candidate handling
      peerConnection.onicecandidate = (event) => {
        if (event.candidate) {
          console.log('üßä Sending ICE candidate:', event.candidate.type, event.candidate.candidate.substring(0, 50) + '...');
          chatSocket.emit('ice-candidate', {
            callId: currentCall.callId,
            candidate: event.candidate
          });
        } else {
          console.log('üßä ICE gathering completed (null candidate received)');
        }
      };

      // ‚úÖ FIX: Proper remote stream handling with audio autoplay
      peerConnection.ontrack = (event) => {
        console.log('üì• REMOTE TRACK RECEIVED:', event.track.kind, 'state:', event.track.readyState);
        
        const [remoteStream] = event.streams;
        if (!remoteStream) {
          console.error('‚ùå No remote stream in ontrack event');
          return;
        }

        console.log('üì• Remote stream details:', {
          id: remoteStream.id,
          active: remoteStream.active,
          audioTracks: remoteStream.getAudioTracks().length,
          videoTracks: remoteStream.getVideoTracks().length
        });

        // Handle remote audio track
        if (event.track.kind === 'audio') {
          console.log('üîä Setting up remote AUDIO track...');
          setupRemoteAudio(remoteStream);
        }

        // Handle remote video track
        if (event.track.kind === 'video' && callType === 'video') {
          console.log('üìπ Setting up remote VIDEO track...');
          setupRemoteVideo(remoteStream);
        }
      };

      // ‚úÖ FIX: Ensure local tracks are properly added
      if (!localStream) {
        throw new Error('Local stream must be obtained before creating peer connection');
      }

      console.log('üé§ Adding local tracks to peer connection...');
      localStream.getTracks().forEach((track, index) => {
        console.log(`üé§ Adding track ${index}:`, track.kind, 'enabled:', track.enabled, 'state:', track.readyState);
        
        // Ensure track is enabled
        track.enabled = true;
        
        // Add track to peer connection
        peerConnection.addTrack(track, localStream);
        console.log(`‚úÖ Track ${index} (${track.kind}) added to peer connection`);
      });

      // Verify tracks were added
      const senders = peerConnection.getSenders();
      console.log('üé§ Total senders after adding tracks:', senders.length);
      senders.forEach((sender, index) => {
        if (sender.track) {
          console.log(`üé§ Sender ${index}: ${sender.track.kind} track`);
        }
      });

      // ICE connection state monitoring
      peerConnection.oniceconnectionstatechange = () => {
        console.log('üßä ICE connection state:', peerConnection.iceConnectionState);
        if (peerConnection.iceConnectionState === 'failed') {
          console.log('üîÑ ICE connection failed, attempting restart...');
          peerConnection.restartIce();
        }
      };

      console.log('‚úÖ Peer connection created and configured successfully');
      return peerConnection;
    }

    function setupRemoteAudio(remoteStream) {
      console.log('üîä Setting up remote audio stream...');

      // Verify audio tracks exist
      const audioTracks = remoteStream.getAudioTracks();
      if (audioTracks.length === 0) {
        console.error('‚ùå No audio tracks in remote stream');
        return;
      }

      console.log('üîä Remote audio tracks:', audioTracks.length);
      audioTracks.forEach((track, i) => {
        console.log(`üîä Track ${i}: enabled=${track.enabled}, muted=${track.muted}, state=${track.readyState}`);
      });

      // Remove any existing remote audio element
      const existingAudio = document.getElementById('remote-audio');
      if (existingAudio) {
        existingAudio.srcObject = null;
        existingAudio.remove();
        console.log('üîä Removed existing remote audio element');
      }

      // ‚úÖ FIX: Create audio element with proper WebRTC settings
      const audio = document.createElement('audio');
      audio.id = 'remote-audio';
      audio.srcObject = remoteStream;
      audio.autoplay = true;
      audio.playsInline = true;
      audio.controls = false;
      audio.volume = 1.0;
      audio.muted = false;

      // Essential attributes for WebRTC audio
      audio.setAttribute('autoplay', '');
      audio.setAttribute('playsinline', '');

      // Hide but keep in DOM for functionality
      audio.style.cssText = 'position: absolute; left: -10000px; width: 1px; height: 1px; opacity: 0.01;';

      // Add to DOM immediately
      document.body.appendChild(audio);
      console.log('üîä Remote audio element created and added to DOM');

      // ‚úÖ FIX: Enhanced event handling for reliable playback
      audio.onloadedmetadata = () => {
        console.log('üîä Remote audio metadata loaded');
        attemptAudioPlay(audio);
      };

      audio.oncanplay = () => {
        console.log('üîä Remote audio can play');
        attemptAudioPlay(audio);
      };

      audio.onplay = () => {
        console.log('‚úÖ REMOTE AUDIO STARTED PLAYING!');
        // Verify playback after a moment
        setTimeout(() => {
          if (!audio.paused && audio.currentTime >= 0) {
            console.log('‚úÖ Remote audio playback confirmed, currentTime:', audio.currentTime);
          }
        }, 500);
      };

      audio.onpause = () => {
        console.warn('‚è∏Ô∏è Remote audio paused unexpectedly');
        if (remoteStream.active && !audio.ended) {
          console.log('üîÑ Attempting to resume remote audio...');
          attemptAudioPlay(audio);
        }
      };

      audio.onerror = (e) => {
        console.error('‚ùå Remote audio error:', audio.error);
      };

      // Store globally for debugging
      window.remoteAudio = audio;

      return audio;
    }

    function attemptAudioPlay(audioElement) {
      if (!audioElement) {
        console.error('‚ùå No audio element provided');
        return;
      }

      console.log('üîä Attempting to play remote audio...', {
        paused: audioElement.paused,
        readyState: audioElement.readyState,
        currentTime: audioElement.currentTime,
        srcObject: !!audioElement.srcObject
      });

      // Check if already playing
      if (!audioElement.paused && audioElement.currentTime > 0) {
        console.log('üîä Audio is already playing');
        return;
      }

      // ‚úÖ FIX: Force play with better error handling
      const playPromise = audioElement.play();
      
      if (playPromise !== undefined) {
        playPromise.then(() => {
          console.log('‚úÖ REMOTE AUDIO PLAY PROMISE RESOLVED!');
          
          // Verify playback
          setTimeout(() => {
            if (audioElement.paused) {
              console.warn('‚ö†Ô∏è Audio paused after play promise, retrying...');
              audioElement.play().catch(console.error);
            } else {
              console.log('‚úÖ Remote audio confirmed playing');
            }
          }, 500);
          
        }).catch(error => {
          console.error('‚ùå Remote audio play failed:', error.name, error.message);
          
          if (error.name === 'NotAllowedError') {
            console.log('üîä Autoplay blocked - user interaction needed');
            showAudioAutoplayNotification();
          } else {
            console.log('üîÑ Retrying audio play...');
            setTimeout(() => attemptAudioPlay(audioElement), 1000);
          }
        });
      }
    }

    function checkAudioStream(audioElement) {
      if (!audioElement || !audioElement.srcObject) {
        console.error('‚ùå No audio element or stream');
        return;
      }

      const stream = audioElement.srcObject;
      const audioTracks = stream.getAudioTracks();

      console.log('üîä Audio stream check:', {
        streamActive: stream.active,
        audioTracks: audioTracks.length,
        trackStates: audioTracks.map(t => ({
          enabled: t.enabled,
          muted: t.muted,
          readyState: t.readyState
        }))
      });

      // Try to refresh the stream
      if (stream.active && audioTracks.length > 0) {
        console.log('üîÑ Refreshing audio element...');
        audioElement.load();
        setTimeout(() => attemptAudioPlay(audioElement), 500);
      }
    }

    function setupAutoplayHandler(audioElement) {
      // Show notification
      showAudioPlaybackNotification();

      // Set up interaction handler
      const interactionHandler = (event) => {
        console.log('üîä User interaction detected:', event.type);

        audioElement.play().then(() => {
          console.log('‚úÖ Audio started after user interaction');
          cleanup();
        }).catch(err => {
          console.error('‚ùå Still failed to play after interaction:', err);
          cleanup();
        });
      };

      const cleanup = () => {
        document.removeEventListener('click', interactionHandler, true);
        document.removeEventListener('touchstart', interactionHandler, true);
        document.removeEventListener('keydown', interactionHandler, true);
        hideAudioPlaybackNotification();
      };

      // Listen for any user interaction with capture
      document.addEventListener('click', interactionHandler, true);
      document.addEventListener('touchstart', interactionHandler, true);
      document.addEventListener('keydown', interactionHandler, true);

      // Auto cleanup after 10 seconds
      setTimeout(cleanup, 10000);
    }

    function setupRemoteVideo(remoteStream) {
      const remoteVideo = document.getElementById('remote-video');
      if (!remoteVideo) {
        console.error('‚ùå Remote video element not found');
        return;
      }

      console.log('üìπ Setting up remote video');
      remoteVideo.srcObject = remoteStream;
      remoteVideo.autoplay = true;
      remoteVideo.playsinline = true;
      remoteVideo.muted = false;

      remoteVideo.onloadedmetadata = () => {
        console.log('üìπ Remote video metadata loaded');
        remoteVideo.play().catch(err => {
          console.error('‚ùå Error playing remote video:', err);
        });
      };
    }

    function verifyAudioFlow() {
      console.log('üîä Verifying audio flow...');

      if (!peerConnection) {
        console.error('‚ùå No peer connection for audio verification');
        return;
      }

      // Check transceivers
      const transceivers = peerConnection.getTransceivers();
      const audioTransceivers = transceivers.filter(t => t.receiver.track && t.receiver.track.kind === 'audio');

      console.log('üîä Audio transceivers:', audioTransceivers.length);
      audioTransceivers.forEach((transceiver, index) => {
        console.log(`üîä Audio transceiver ${index}:`, {
          direction: transceiver.direction,
          currentDirection: transceiver.currentDirection,
          trackEnabled: transceiver.receiver.track.enabled,
          trackMuted: transceiver.receiver.track.muted,
          trackReadyState: transceiver.receiver.track.readyState
        });
      });

      // Check remote audio element
      const remoteAudio = document.getElementById('remote-audio');
      if (remoteAudio) {
        console.log('üîä Remote audio element state:', {
          paused: remoteAudio.paused,
          muted: remoteAudio.muted,
          volume: remoteAudio.volume,
          currentTime: remoteAudio.currentTime,
          readyState: remoteAudio.readyState
        });

        if (remoteAudio.paused) {
          console.log('üîä Remote audio is paused, attempting to resume...');
          attemptAudioPlay(remoteAudio);
        }
      }
    }

    let audioNotification = null;

    function showAudioPlaybackNotification() {
      if (audioNotification) return;

      console.log('üîä Showing audio playback notification');

      audioNotification = document.createElement('div');
      audioNotification.id = 'audio-notification';
      audioNotification.style.cssText = `
        position: fixed;
        top: 20px;
        right: 20px;
        background: linear-gradient(45deg, #4CAF50, #45a049);
        color: white;
        padding: 16px 20px;
        border-radius: 12px;
        font-size: 14px;
        font-weight: 500;
        z-index: 10001;
        box-shadow: 0 6px 20px rgba(0,0,0,0.3);
        cursor: pointer;
        animation: slideIn 0.3s ease-out;
        max-width: 300px;
        text-align: center;
      `;

      audioNotification.innerHTML = `
        <div style="display: flex; align-items: center; gap: 10px;">
          <div style="width: 20px; height: 20px; background: rgba(255,255,255,0.3); border-radius: 50%; display: flex; align-items: center; justify-content: center;">
            üîä
          </div>
          <div>
            <div style="font-weight: bold;">Enable Audio</div>
            <div style="font-size: 12px; opacity: 0.9;">Click anywhere to hear voice</div>
          </div>
        </div>
      `;

      document.body.appendChild(audioNotification);

      // Add CSS animation
      const style = document.createElement('style');
      style.textContent = `
        @keyframes slideIn {
          from { transform: translateX(100%); opacity: 0; }
          to { transform: translateX(0); opacity: 1; }
        }
      `;
      document.head.appendChild(style);
    }

    function hideAudioPlaybackNotification() {
      if (audioNotification && audioNotification.parentNode) {
        console.log('üîä Hiding audio playback notification');
        audioNotification.parentNode.removeChild(audioNotification);
        audioNotification = null;
      }
    }

    async function handleCallAccepted(data) {
      console.log('üü¢ CALL ACCEPTED - Starting WebRTC negotiation...');

      try {
        // ‚úÖ Keep UI in calling state - will update when connection established
        console.log('üìû Keeping caller UI in calling state until connected');

        // Verify we have local stream
        if (!localStream || localStream.getTracks().length === 0) {
          console.error('‚ùå No local stream available');
          throw new Error('Local stream not available');
        }

        // Create peer connection with local tracks
        console.log('üîó Creating peer connection for caller...');
        await createPeerConnection();

        // ‚úÖ FIX: Create offer with proper constraints
        console.log('üì§ Creating offer...');
        const offerOptions = {
          offerToReceiveAudio: true,
          offerToReceiveVideo: callType === 'video'
        };

        const offer = await peerConnection.createOffer(offerOptions);
        console.log('‚úÖ Offer created:', offer.type);

        // Set local description
        console.log('üì§ Setting local description...');
        await peerConnection.setLocalDescription(offer);
        console.log('‚úÖ Local description set successfully');

        // Send offer via Socket.IO
        console.log('üì§ Sending offer to receiver via Socket.IO...');
        chatSocket.emit('call-offer', {
          callId: currentCall.callId,
          offer: offer
        });
        console.log('‚úÖ Offer sent to receiver');

      } catch (error) {
        console.error('‚ùå Error in handleCallAccepted:', error);
        alert('Failed to establish call: ' + error.message);
        endCall();
      }
    }

    async function handleCallOffer(data) {
      console.log('üì• Handling call offer');

      try {
        if (!currentCall) {
          console.error('‚ùå No current call when handling offer');
          return;
        }

        if (!peerConnection) {
          console.log('üîó Creating peer connection for offer...');
          await createPeerConnection();
        }

        console.log('üì• Setting remote description (offer)...');
        const offerDesc = new RTCSessionDescription(data.offer);
        await peerConnection.setRemoteDescription(offerDesc);
        console.log('‚úÖ Remote description (offer) set');

        // Verify local stream before creating answer
        if (!localStream || localStream.getTracks().length === 0) {
          console.error('‚ùå No local stream available when creating answer');
          throw new Error('Local stream not available');
        }

        console.log('üì§ Creating answer with audio constraints...');
        const answerOptions = {
          offerToReceiveAudio: true,
          offerToReceiveVideo: callType === 'video'
        };

        const answer = await peerConnection.createAnswer(answerOptions);
        console.log('‚úÖ Answer created with options:', answerOptions);

        console.log('üì§ Setting local description (answer)...');
        await peerConnection.setLocalDescription(answer);
        console.log('‚úÖ Local description (answer) set');

        console.log('üì§ Sending answer to caller...');
        chatSocket.emit('call-answer', {
          callId: currentCall.callId,
          answer: answer
        });

        console.log('‚úÖ Answer sent successfully');

        // Process any pending ICE candidates
        if (window.pendingIceCandidates && window.pendingIceCandidates.length > 0) {
          console.log(`üßä Processing ${window.pendingIceCandidates.length} pending ICE candidates...`);
          for (const candidate of window.pendingIceCandidates) {
            try {
              await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
              console.log('‚úÖ Pending ICE candidate added');
            } catch (error) {
              console.error('‚ùå Error adding pending ICE candidate:', error);
            }
          }
          window.pendingIceCandidates = [];
        }

        // Verify audio setup
        setTimeout(() => {
          verifyAudioFlow();
        }, 2000);

      } catch (error) {
        console.error('‚ùå Error handling call offer:', error);
        alert('Failed to process call offer: ' + error.message);
        endCall();
      }
    }

    async function handleCallAnswer(data) {
      console.log('üì• RECEIVED ANSWER from receiver');

      try {
        if (!peerConnection) {
          console.error('‚ùå No peer connection when handling answer');
          return;
        }

        console.log('üì• Setting remote description (answer)...');
        await peerConnection.setRemoteDescription(new RTCSessionDescription(data.answer));
        console.log('‚úÖ REMOTE DESCRIPTION SET FROM ANSWER - WebRTC negotiation completing...');

        // ‚úÖ The UI will update automatically when connectionState becomes 'connected'
        console.log('‚è≥ Waiting for peer connection to establish...');

        // Process any queued ICE candidates
        if (window.pendingIceCandidates && window.pendingIceCandidates.length > 0) {
          console.log(`üßä Processing ${window.pendingIceCandidates.length} pending ICE candidates...`);
          for (const candidate of window.pendingIceCandidates) {
            try {
              await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
              console.log('‚úÖ Pending ICE candidate added');
            } catch (error) {
              console.error('‚ùå Error adding pending ICE candidate:', error);
            }
          }
          window.pendingIceCandidates = [];
        }

      } catch (error) {
        console.error('‚ùå Error handling call answer:', error);
        alert('Failed to process call answer');
        endCall();
      }
    }

    async function handleIceCandidate(data) {
      console.log('üì• Received ICE candidate');

      try {
        // Handle null candidate (end of candidates)
        if (!data.candidate || !data.candidate.candidate) {
          console.log('üßä End-of-candidates signal received');
          return;
        }

        console.log('üßä ICE candidate type:', data.candidate.type || 'unknown');

        // ‚úÖ FIX: Robust ICE candidate handling
        if (peerConnection && peerConnection.remoteDescription) {
          console.log('üßä Adding ICE candidate immediately...');
          await peerConnection.addIceCandidate(new RTCIceCandidate(data.candidate));
          console.log('‚úÖ ICE candidate added successfully');
        } else {
          console.log('üßä Queueing ICE candidate (no remote description yet)');
          if (!window.pendingIceCandidates) {
            window.pendingIceCandidates = [];
          }
          window.pendingIceCandidates.push(data.candidate);
          console.log(`üì¶ Queued ICE candidate. Total pending: ${window.pendingIceCandidates.length}`);
        }
      } catch (error) {
        console.error('‚ùå Error handling ICE candidate:', error.name, error.message);
      }
    }

    function handleCallDeclined(data) {
      console.log('Call was declined');
      hideCallInterface();

      // ‚úÖ RESTORE UI: Show message footer after call decline
      const messageFooter = document.getElementById('message-footer');
      if (messageFooter) {
        messageFooter.style.display = 'block';
        console.log('‚úÖ Chat typing bar restored after call decline');
      }

      currentCall = null;
      alert('Call was declined');
    }

    function handleCallTimeout() {
      console.log('Call timed out');
      hideCallInterface();

      // ‚úÖ RESTORE UI: Show message footer after call timeout
      const messageFooter = document.getElementById('message-footer');
      if (messageFooter) {
        messageFooter.style.display = 'block';
        console.log('‚úÖ Chat typing bar restored after call timeout');
      }

      currentCall = null;
      alert('Call timed out');
    }

    function showMissedCallNotification(data) {
      console.log('Showing missed call notification');
    }

    function toggleAudio() {
      if (localStream) {
        const audioTrack = localStream.getAudioTracks()[0];
        if (audioTrack) {
          audioTrack.enabled = !audioTrack.enabled;
          const button = document.getElementById('toggle-audio');
          if (button) {
            button.classList.toggle('bg-red-500', !audioTrack.enabled);
            button.classList.toggle('bg-gray-600', audioTrack.enabled);
          }
        }
      }
    }

    function toggleVideo() {
      if (localStream) {
        const videoTrack = localStream.getVideoTracks()[0];
        if (videoTrack) {
          videoTrack.enabled = !videoTrack.enabled;
          const button = document.getElementById('toggle-video');
          if (button) {
            button.classList.toggle('bg-red-500', !videoTrack.enabled);
            button.classList.toggle('bg-gray-600', videoTrack.enabled);
          }
        }
      }
    }

    function testAudioPlayback() {
      console.log('üîä Testing audio playback...');

      // Test remote audio element
      const remoteAudio = document.getElementById('remote-audio');
      if (remoteAudio) {
        console.log('üîä Remote audio element found:', {
          srcObject: !!remoteAudio.srcObject,
          paused: remoteAudio.paused,
          muted: remoteAudio.muted,
          volume: remoteAudio.volume,
          readyState: remoteAudio.readyState
        });

        if (remoteAudio.srcObject) {
          const tracks = remoteAudio.srcObject.getTracks();
          console.log('üîä Remote audio stream tracks:', tracks.map(t => ({
            kind: t.kind,
            enabled: t.enabled,
            muted: t.muted,
            readyState: t.readyState
          })));
        }

        // Force play the remote audio
        remoteAudio.play().then(() => {
          console.log('‚úÖ Remote audio test play successful');
          alert('Audio test: Remote audio playing');
        }).catch(error => {
          console.error('‚ùå Remote audio test play failed:', error);
          alert('Audio test failed: ' + error.message);
        });
      } else {
        console.error('‚ùå No remote audio element found');
        alert('No remote audio element found');
      }

      // Test peer connection
      if (peerConnection) {
        const receivers = peerConnection.getReceivers();
        const audioReceivers = receivers.filter(r => r.track && r.track.kind === 'audio');
        console.log('üîä Audio receivers:', audioReceivers.length);

        audioReceivers.forEach((receiver, index) => {
          console.log(`üîä Audio receiver ${index}:`, {
            track: !!receiver.track,
            enabled: receiver.track?.enabled,
            muted: receiver.track?.muted,
            readyState: receiver.track?.readyState
          });
        });

        // Log WebRTC stats
        if (window.WebRTCDebugger) {
          WebRTCDebugger.logPeerConnectionStats(peerConnection);
        }
      }

      // Test browser audio capabilities
      console.log('üîä Browser audio capabilities:', {
        audioContext: !!(window.AudioContext || window.webkitAudioContext),
        getUserMedia: !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia),
        webRTC: !!window.RTCPeerConnection
      });
    }

    function hideCallInterface() {
      const callInterface = document.getElementById('call-interface');
      if (callInterface) {
        callInterface.classList.add('hidden');
      }
    }

    function updateCallConnectionStatus(message, color) {
      const statusElement = document.querySelector('#audio-indicator p:last-child');
      if (statusElement) {
        statusElement.textContent = message;
        statusElement.style.color = color;
      }
    }

    function showAudioAutoplayNotification() {
      // Create notification for autoplay issues
      const notification = document.createElement('div');
      notification.id = 'autoplay-notification';
      notification.style.cssText = `
        position: fixed; top: 20px; right: 20px; background: #3b82f6; color: white;
        padding: 12px 16px; border-radius: 8px; font-size: 14px; z-index: 10001;
        box-shadow: 0 4px 12px rgba(0,0,0,0.3); cursor: pointer;
      `;
      notification.innerHTML = `
        <div>üîä Click anywhere to enable audio</div>
        <div style="font-size: 12px; opacity: 0.9;">Browser blocked autoplay</div>
      `;

      document.body.appendChild(notification);

      // Remove on any click
      const enableAudio = () => {
        const remoteAudio = document.getElementById('remote-audio');
        if (remoteAudio) {
          remoteAudio.play().catch(console.error);
        }
        notification.remove();
        document.removeEventListener('click', enableAudio);
      };

      document.addEventListener('click', enableAudio);
      setTimeout(() => {
        if (notification.parentNode) {
          notification.remove();
          document.removeEventListener('click', enableAudio);
        }
      }, 10000);
    }

    function hideCallNotification() {
      const notification = document.getElementById('incoming-call-notification');
      if (notification) {
        notification.classList.add('hidden');
      }
    }

    // Voice message playback functionality
    let currentAudio = null;
    let currentPlayButton = null;

    // Initialize voice message players
    function initializeVoiceMessages() {
      const voiceButtons = document.querySelectorAll('.voice-play-btn');
      voiceButtons.forEach(button => {
        button.addEventListener('click', function() {
          const audioSrc = this.dataset.audioSrc;
          toggleVoiceMessage(this, audioSrc);
        });
      });
    }

    function toggleVoiceMessage(button, audioSrc) {
      const container = button.closest('.voice-message-container');
      const progressBar = container.querySelector('.voice-progress');
      const durationElement = container.querySelector('.voice-duration');
      const playIcon = button.querySelector('.play-icon');
      const pauseIcon = button.querySelector('.pause-icon');

      // Stop any currently playing audio
      if (currentAudio && !currentAudio.paused && currentPlayButton !== button) {
        currentAudio.pause();
        resetPreviousButton();
      }

      if (currentAudio && currentPlayButton === button) {
        // Toggle current audio
        if (currentAudio.paused) {
          currentAudio.play().then(() => {
            playIcon.classList.add('hidden');
            pauseIcon.classList.remove('hidden');
          }).catch(error => {
            console.error('Error playing audio:', error);
            showNotification('Failed to play voice message', 'error');
          });
        } else {
          currentAudio.pause();
          playIcon.classList.remove('hidden');
          pauseIcon.classList.add('hidden');
        }
        return;
      }

      // Create new audio element with proper settings
      currentAudio = new Audio();
      currentAudio.src = audioSrc;
      currentAudio.preload = 'auto';
      currentAudio.volume = 1.0;
      currentPlayButton = button;

      // Handle CORS and audio format issues
      currentAudio.crossOrigin = 'anonymous';

      // Set up event listeners
      currentAudio.addEventListener('loadedmetadata', function() {
        const duration = formatTime(currentAudio.duration);
        durationElement.textContent = duration;
      });

      currentAudio.addEventListener('timeupdate', function() {
        if (currentAudio.duration) {
          const progress = (currentAudio.currentTime / currentAudio.duration) * 100;
          progressBar.style.width = progress + '%';
          durationElement.textContent = formatTime(currentAudio.currentTime);
        }
      });

      currentAudio.addEventListener('ended', function() {
        resetAudioPlayer(button, progressBar, durationElement);
      });

      currentAudio.addEventListener('error', function(e) {
        console.error('Audio error:', e);
        showNotification('Failed to load voice message', 'error');
        resetAudioPlayer(button, progressBar, durationElement);
      });

      // Load and play the audio
      currentAudio.load();

      // Wait for audio to be ready
      currentAudio.addEventListener('canplaythrough', function() {
        currentAudio.play().then(() => {
          playIcon.classList.add('hidden');
          pauseIcon.classList.remove('hidden');
        }).catch(error => {
          console.error('Error playing audio:', error);
          handleAudioError(error, audioSrc);
        });
      }, { once: true });

      // Add click handler to progress bar for seeking
      const progressBarContainer = container.querySelector('.voice-progress-bar-container');
      progressBarContainer.addEventListener('click', function(e) {
        if (currentAudio && currentAudio.duration) {
          const rect = this.getBoundingClientRect();
          const clickX = e.clientX - rect.left;
          const width = rect.width;
          const seekTime = (clickX / width) * currentAudio.duration;
          currentAudio.currentTime = seekTime;
        }
      });
    }

    function resetPreviousButton() {
      if (currentPlayButton) {
        const playIcon = currentPlayButton.querySelector('.play-icon');
        const pauseIcon = currentPlayButton.querySelector('.pause-icon');
        const container = currentPlayButton.closest('.voice-message-container');
        const progressBar = container.querySelector('.voice-progress');
        const durationElement = container.querySelector('.voice-duration');

        playIcon.classList.remove('hidden');
        pauseIcon.classList.add('hidden');
        progressBar.style.width = '0%';
        if (currentAudio && currentAudio.duration) {
          durationElement.textContent = formatTime(currentAudio.duration);
        }
      }
    }

    function resetAudioPlayer(button, progressBar, durationElement) {
      const playIcon = button.querySelector('.play-icon');
      const pauseIcon = button.querySelector('.pause-icon');

      playIcon.classList.remove('hidden');
      pauseIcon.classList.add('hidden');
      progressBar.style.width = '0%';

      if (currentAudio && currentAudio.duration) {
        durationElement.textContent = formatTime(currentAudio.duration);
      }
    }

    function formatTime(seconds) {
      if (isNaN(seconds)) return '0:00';
      const mins = Math.floor(seconds / 60);
      const secs = Math.floor(seconds % 60);
      return `${mins}:${secs.toString().padStart(2, '0')}`;
    }

    // Handle audio errors
    function handleAudioError(error, audioSrc) {
      console.error('Audio playback error:', error);

      // Try alternative approach with HTML5 audio element
      const tempAudio = document.createElement('audio');
      tempAudio.src = audioSrc;
      tempAudio.controls = true;
      tempAudio.style.display = 'none';
      document.body.appendChild(tempAudio);

      tempAudio.play().then(() => {
        document.body.removeChild(tempAudio);
        showNotification('Voice message played successfully', 'success');
      }).catch(() => {
        document.body.removeChild(tempAudio);
        showNotification('Unable to play voice message. Your browser may not support this audio format.', 'error');
      });
    }

    // Show notification function
    function showNotification(message, type = 'info') {
      if (window.ModernChat && window.ModernChat.showNotification) {
        window.ModernChat.showNotification(message, type);
      } else {
        // Create a simple notification
        const notification = document.createElement('div');
        notification.className = `fixed top-4 right-4 z-50 p-4 rounded-lg shadow-lg ${
          type === 'error' ? 'bg-red-500' : type === 'success' ? 'bg-green-500' : 'bg-blue-500'
        } text-white`;
        notification.textContent = message;
        document.body.appendChild(notification);

        setTimeout(() => {
          if (notification.parentNode) {
            notification.parentNode.removeChild(notification);
          }
        }, 3000);
      }
    }

    // Auto-scroll functionality
    let isUserScrolling = false;
    let scrollTimeout = null;
    let newMessageIndicator = null;

    // Helper function to scroll to bottom
    function scrollToBottom(smooth = true) {
      const container = document.getElementById('messages-container');
      if (!container) {
        console.warn('Messages container not found for scrolling');
        return;
      }

      console.log('üìú Scrolling to bottom, smooth:', smooth);

      if (smooth) {
        container.scrollTo({
          top: container.scrollHeight,
          behavior: 'smooth'
        });
      } else {
        container.scrollTop = container.scrollHeight;
      }
    }

    // Check if user is near bottom of chat
    function isNearBottom() {
      const container = document.getElementById('messages-container');
      if (!container) return true;

      const threshold = 100; // pixels from bottom
      const isNear = container.scrollTop + container.clientHeight >= container.scrollHeight - threshold;
      console.log('üìú Is near bottom:', isNear, {
        scrollTop: container.scrollTop,
        clientHeight: container.clientHeight,
        scrollHeight: container.scrollHeight,
        threshold: threshold
      });
      return isNear;
    }

    // Create and show new message indicator
    function showNewMessageIndicator() {
      if (newMessageIndicator) return; // Already showing

      console.log('üìú Showing new message indicator');

      newMessageIndicator = document.createElement('div');
      newMessageIndicator.id = 'new-message-indicator';
      newMessageIndicator.className = 'fixed bottom-28 left-1/2 transform -translate-x-1/2 bg-primary-500 text-white px-4 py-2 rounded-full shadow-lg cursor-pointer hover:bg-primary-600 transition-all duration-200 z-40 animate-bounce';
      newMessageIndicator.innerHTML = `
        <div class="flex items-center space-x-2">
          <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 14l-7 7m0 0l-7-7m7 7V3"></path>
          </svg>
          <span class="text-sm font-medium">New Messages</span>
        </div>
      `;

      newMessageIndicator.addEventListener('click', () => {
        console.log('üìú New message indicator clicked, scrolling to bottom');
        hideNewMessageIndicator();
        scrollToBottom(true);
      });

      document.body.appendChild(newMessageIndicator);
    }

    // Hide new message indicator
    function hideNewMessageIndicator() {
      if (newMessageIndicator) {
        console.log('üìú Hiding new message indicator');
        newMessageIndicator.remove();
        newMessageIndicator = null;
      }
    }

    // Initialize scroll behavior
    function initializeScrollBehavior() {
      const container = document.getElementById('messages-container');
      if (!container) {
        console.warn('Messages container not found for scroll initialization');
        return;
      }

      console.log('üìú Initializing scroll behavior');

      // Detect user scrolling
      container.addEventListener('scroll', () => {
        clearTimeout(scrollTimeout);
        isUserScrolling = true;

        // Check if user scrolled to bottom, hide indicator if so
        if (isNearBottom()) {
          hideNewMessageIndicator();
        }

        // Reset user scrolling flag after scroll ends
        scrollTimeout = setTimeout(() => {
          isUserScrolling = false;
          console.log('üìú User stopped scrolling');
        }, 150);
      });

      // Auto-scroll to bottom when chat opens
      console.log('üìú Auto-scrolling to bottom on chat open');
      setTimeout(() => {
        scrollToBottom(false); // No smooth scroll on initial load
      }, 100);
    }

    // Chat message functions
    async function sendMessage(e) {
      e.preventDefault();

      const messageInput = document.getElementById('message-input');
      const mediaInput = document.getElementById('media-input');
      const message = messageInput.value.trim();
      const file = mediaInput.files[0];

      if (!message && !file) return;

      const formData = new FormData();
      if (message) formData.append('msg', message);
      if (file) formData.append('media', file);

      try {
        const response = await fetch(`/chat/${otherUserId}`, {
          method: 'POST',
          body: formData
        });

        if (response.ok) {
          messageInput.value = '';
          mediaInput.value = '';
          hideFilePreview();

          // Auto-scroll after sending message
          console.log('üìú Message sent, auto-scrolling to bottom');
          setTimeout(() => scrollToBottom(true), 100);
        }
      } catch (error) {
        console.error('Error sending message:', error);
      }
    }

    function appendMessage(message) {
      const container = document.getElementById('messages-container');
      const messageDiv = document.createElement('div');

      console.log('üìú Appending new message from:', message.from.username);

      // Add message to DOM (simplified version)
      messageDiv.innerHTML = `
        <div class="flex ${message.from._id === currentUserId ? 'justify-end' : 'justify-start'}">
          <div class="max-w-xs lg:max-w-md px-4 py-3 rounded-2xl ${
            message.from._id === currentUserId ? 
            'bg-gradient-to-r from-primary-500 to-primary-600 text-white rounded-br-md' : 
            'bg-white/80 backdrop-blur-lg text-secondary-900 rounded-bl-md border border-white/20'
          } shadow-lg">
            <p class="text-sm leading-relaxed">${message.msg}</p>
            <span class="text-xs ${message.from._id === currentUserId ? 'text-primary-100' : 'text-secondary-500'}">
              ${new Date(message.created_at).toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit' })}
            </span>
          </div>
        </div>
      `;

      container.appendChild(messageDiv);

      // Handle auto-scroll for new messages
      if (message.from._id === currentUserId) {
        // Always auto-scroll for own messages
        console.log('üìú Own message, auto-scrolling to bottom');
        setTimeout(() => scrollToBottom(true), 100);
      } else {
        // For other users' messages, check if user is scrolled up
        if (isNearBottom() && !isUserScrolling) {
          console.log('üìú User near bottom, auto-scrolling to new message');
          setTimeout(() => scrollToBottom(true), 100);
        } else {
          console.log('üìú User scrolled up, showing new message indicator');
          showNewMessageIndicator();
        }
      }
    }

    function appendVoiceMessage(data) {
      console.log('‚úÖ Voice message received', data);

      const container = document.getElementById('messages-container');
      const messageDiv = document.createElement('div');
      const isOwn = data.from === currentUserId;
      const timestamp = new Date(data.timestamp).toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit' });

      // Create blob URL from array buffer
      const audioBlob = new Blob([data.audio], { type: data.mimeType || 'audio/webm' });
      const audioUrl = URL.createObjectURL(audioBlob);

      // Create voice message HTML
      messageDiv.className = `flex ${isOwn ? 'justify-end' : 'justify-start'}`;
      messageDiv.innerHTML = `
        <div class="max-w-xs lg:max-w-md">
          <div class="${isOwn ? 'bg-gradient-to-r from-primary-500 to-primary-600' : 'bg-gradient-to-r from-indigo-500 to-purple-600'} rounded-2xl ${isOwn ? 'rounded-br-md' : 'rounded-bl-md'} p-3 shadow-lg relative group">
            <div class="flex items-center space-x-3">
              <button class="voice-play-btn flex-shrink-0 bg-white bg-opacity-20 border-2 border-white border-opacity-30 rounded-full w-10 h-10 flex items-center justify-center hover:bg-opacity-30 transition-all duration-200" data-audio-src="${audioUrl}">
                <svg class="play-icon w-5 h-5 text-white ml-0.5" fill="currentColor" viewBox="0 0 20 20">
                  <path d="M8 5v10l7-5-7-5z"/>
                </svg>
                <svg class="pause-icon w-5 h-5 text-white hidden" fill="currentColor" viewBox="0 0 20 20">
                  <path fill-rule="evenodd" d="M6 4a1 1 0 011 1v10a1 1 0 11-2 0V5a1 1 0 011-1zM13 4a1 1 0 011 1v10a1 1 0 11-2 0V5a1 1 0 011-1z" clip-rule="evenodd"/>
                </svg>
              </button>
              <div class="flex-1 min-w-0">
                <div class="voice-progress-bar-container h-1 bg-white bg-opacity-30 rounded-full cursor-pointer">
                  <div class="voice-progress h-full bg-white rounded-full transition-all duration-100" style="width: 0%"></div>
                </div>
              </div>
              <div class="voice-duration text-white text-sm font-medium min-w-10 text-right">0:00</div>
            </div>
          </div>
          <div class="flex items-center justify-between mt-1 px-2">
            <span class="text-xs text-secondary-500">${timestamp}</span>
          </div>
        </div>
      `;

      container.appendChild(messageDiv);

      // Initialize the voice player for this new message
      const playButton = messageDiv.querySelector('.voice-play-btn');
      if (playButton) {
        playButton.addEventListener('click', function() {
          toggleVoiceMessage(this, audioUrl);
        });
      }

      // Handle auto-scroll for new voice messages
      if (isOwn) {
        console.log('üìú Own voice message, auto-scrolling to bottom');
        setTimeout(() => scrollToBottom(true), 100);
      } else {
        if (isNearBottom() && !isUserScrolling) {
          console.log('üìú User near bottom, auto-scrolling to new voice message');
          setTimeout(() => scrollToBottom(true), 100);
        } else {
          console.log('üìú User scrolled up, showing new message indicator');
          showNewMessageIndicator();
        }
      }

      console.log('‚úÖ Voice message appended to chat');
    }

    function showTypingIndicator(data) {
      if (data.isTyping) {
        document.getElementById('typing-indicator-container').classList.remove('hidden');
        document.getElementById('typing-text').textContent = `${data.username} is typing...`;
      } else {
        document.getElementById('typing-indicator-container').classList.add('hidden');
      }
    }

    function hideFilePreview() {
      document.getElementById('filePreview').classList.add('hidden');
    }

    // AI and media functions
    async function summarizeContent(messageId, type, content) {
      console.log('üìù Summarizing content:', type);

      const modal = document.getElementById('ai-summary-modal');
      const loadingDiv = document.getElementById('ai-summary-loading');
      const contentDiv = document.getElementById('ai-summary-content');

      if (modal) {
        modal.classList.remove('hidden');
        loadingDiv.classList.remove('hidden');
        contentDiv.classList.add('hidden');
      }

      try {
        const response = await fetch('/api/ai/summarize', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            messageId: messageId,
            type: type,
            content: content
          })
        });

        const result = await response.json();

        if (result.success && contentDiv) {
          contentDiv.innerHTML = result.summary.replace(/\n/g, '<br>');
          loadingDiv.classList.add('hidden');
          contentDiv.classList.remove('hidden');
        } else {
          throw new Error(result.error || 'Failed to generate summary');
        }

      } catch (error) {
        console.error('‚ùå Error generating summary:', error);
        if (contentDiv) {
          contentDiv.innerHTML = '‚ùå Failed to generate summary: ' + error.message;
          loadingDiv.classList.add('hidden');
          contentDiv.classList.remove('hidden');
        }
      }
    }

    async function generateAIResponse() {
      console.log('ü§ñ Generating AI response...');

      try {
        // Get conversation history from the page
        const conversationHistory = [];
        const messages = document.querySelectorAll('#messages-container > div');

        // Extract last 10 messages for context
        const recentMessages = Array.from(messages).slice(-10);

        recentMessages.forEach(messageDiv => {
          const messageContent = messageDiv.querySelector('p');
          const isOwn = messageDiv.querySelector('.from-primary-500, .bg-gradient-to-r');

          if (messageContent && messageContent.textContent.trim()) {
            conversationHistory.push({
              from: isOwn ? '<%= currentUser.username %>' : '<%= otherUser.username %>',
              message: messageContent.textContent.trim(),
              isOwn: !!isOwn
            });
          }
        });

        if (conversationHistory.length === 0) {
          console.warn('‚ö†Ô∏è No conversation history found');
          showNotification('No messages to generate response from', 'warning');
          return;
        }

        console.log('ü§ñ Sending conversation history:', conversationHistory.length, 'messages');

        // Generate AI response
        const response = await fetch(`/api/ai/generate-reply/${otherUserId}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            conversationHistory: conversationHistory
          })
        });

        const result = await response.json();

        if (result.success && result.replies && result.replies.length > 0) {
          console.log('‚úÖ AI responses generated:', result.replies.length);
          showSmartRepliesPanel(result.replies);
        } else {
          throw new Error(result.error || 'No replies generated');
        }

      } catch (error) {
        console.error('‚ùå Error generating AI response:', error);
        showNotification('Failed to generate AI response: ' + error.message, 'error');
      }
    }

    function showSmartRepliesPanel(replies) {
      console.log('ü§ñ Showing smart replies panel with', replies.length, 'replies');

      const panel = document.getElementById('smart-replies-panel');
      const content = document.getElementById('smart-replies-content');

      if (!panel || !content) {
        console.error('‚ùå Smart replies panel elements not found');
        return;
      }

      // Clear existing content
      content.innerHTML = '';

      // Create reply buttons
      replies.forEach((reply, index) => {
        const button = document.createElement('button');
        button.className = 'bg-white hover:bg-gray-50 border border-gray-200 rounded-lg px-3 py-2 text-sm text-left transition-colors duration-200 w-full';
        button.textContent = reply;
        button.onclick = () => sendSmartReply(reply);
        content.appendChild(button);
      });

      // Show panel
      panel.classList.remove('hidden');

      // Auto-hide after 30 seconds
      setTimeout(() => {
        panel.classList.add('hidden');
      }, 30000);
    }

    function sendSmartReply(reply) {
      console.log('ü§ñ Sending smart reply:', reply);

      // Set the reply in the message input
      const messageInput = document.getElementById('message-input');
      if (messageInput) {
        messageInput.value = reply;
        messageInput.focus();
      }

      // Hide the panel
      hideSmartReplies();
    }

    function hideSmartReplies() {
      const panel = document.getElementById('smart-replies-panel');
      if (panel) panel.classList.add('hidden');
    }

    function openMediaPreview(src, type, name) {
      console.log('Opening media preview:', type);
    }

    function closeMediaPreview() {
      const modal = document.getElementById('mediaPreviewModal');
      if (modal) modal.classList.add('hidden');
    }

    function closeAISummary() {
      const modal = document.getElementById('ai-summary-modal');
      if (modal) modal.classList.add('hidden');
    }

    function closeAISummaryOnOutsideClick(event) {
      if (event.target === event.currentTarget) {
        closeAISummary();
      }
    }

    // Voice recording functionality
    let mediaRecorder = null;
    let recordedChunks = [];
    let isRecording = false;
    let recordingStream = null;

    async function startVoiceRecording() {
      console.log('üéôÔ∏è Recording started');

      try {
        // Request microphone access with explicit permissions check
        recordingStream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 44100,
            channelCount: 1
          }
        });

        // Verify we got the stream
        if (!recordingStream || recordingStream.getTracks().length === 0) {
          throw new Error('Failed to get audio stream');
        }

        console.log('üéôÔ∏è Microphone access granted, stream tracks:', recordingStream.getTracks().length);

        // Initialize MediaRecorder with proper settings
        let options = { mimeType: 'audio/webm;codecs=opus' };

        // Check browser support and fallback
        if (!MediaRecorder.isTypeSupported(options.mimeType)) {
          options.mimeType = 'audio/webm';
          if (!MediaRecorder.isTypeSupported(options.mimeType)) {
            options.mimeType = 'audio/ogg';
            if (!MediaRecorder.isTypeSupported(options.mimeType)) {
              options.mimeType = '';
            }
          }
        }

        console.log('üéôÔ∏è Using MIME type:', options.mimeType || 'default');

        mediaRecorder = new MediaRecorder(recordingStream, options);
        recordedChunks = []; // Reset chunks array
        isRecording = true;

        // Handle data available event - collect audio chunks
        mediaRecorder.ondataavailable = (event) => {
          console.log('üì© Voice message chunk available:', event.data.size, 'bytes');
          if (event.data && event.data.size > 0) {
            recordedChunks.push(event.data);
          }
        };

        // Handle recording stop - process and send audio
        mediaRecorder.onstop = async () => {
          console.log('üõë Recording stopped, sending...', recordedChunks.length, 'chunks');

          if (recordedChunks.length > 0) {
            // Create audio blob from chunks
            const mimeType = mediaRecorder.mimeType || 'audio/webm';
            const audioBlob = new Blob(recordedChunks, { type: mimeType });

            console.log('üéôÔ∏è Audio blob created:', {
              size: audioBlob.size,
              type: audioBlob.type,
              chunks: recordedChunks.length
            });

            // Verify blob has content
            if (audioBlob.size === 0) {
              throw new Error('Recording failed - no audio data captured');
            }

            // Send voice message
            await sendVoiceMessage(audioBlob);
          } else {
            console.error('‚ùå No audio chunks recorded');
            alert('Recording failed - no audio data captured');
          }

          // Clean up resources
          cleanupRecording();
        };

        mediaRecorder.onerror = (event) => {
          console.error('‚ùå MediaRecorder error:', event.error);
          cleanupRecording();
        };

        // Start recording with shorter intervals for better chunk collection
        mediaRecorder.start(100); // Collect data every 100ms
        showVoiceRecordingModal();

        console.log('üéôÔ∏è MediaRecorder started, state:', mediaRecorder.state);

      } catch (error) {
        console.error('‚ùå Error starting voice recording:', error);

        let errorMessage = 'Failed to start voice recording';
        if (error.name === 'NotAllowedError') {
          errorMessage = 'Microphone access denied. Please allow microphone permissions and try again.';
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'No microphone found. Please connect a microphone and try again.';
        } else if (error.name === 'NotReadableError') {
          errorMessage = 'Microphone is being used by another application.';
        }

        alert(errorMessage);
        cleanupRecording();
      }
    }

    function stopVoiceRecording() {
      console.log('üõë Stopping voice recording...');

      if (mediaRecorder && isRecording && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
        isRecording = false;
      }
    }

    function cancelVoiceRecording() {
      console.log('üõë Cancelling voice recording...');

      if (mediaRecorder && isRecording && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
      }

      // Clear chunks to prevent sending
      recordedChunks = [];
      isRecording = false;
      cleanupRecording();
      hideVoiceRecordingModal();
    }

    function cleanupRecording() {
      if (recordingStream) {
        recordingStream.getTracks().forEach(track => {
          track.stop();
          console.log('üéôÔ∏è Stopped audio track');
        });
        recordingStream = null;
      }
      isRecording = false;
    }

    function showVoiceRecordingModal() {
      const modal = document.getElementById('voice-recording-modal');
      if (modal) {
        modal.classList.remove('hidden');
      }
    }

    function hideVoiceRecordingModal() {
      const modal = document.getElementById('voice-recording-modal');
      if (modal) {
        modal.classList.add('hidden');
      }
    }

    async function sendVoiceMessage(audioBlob) {
      console.log('üì© Sending voice message...', audioBlob.size, 'bytes');

      try {
        // Create form data
        const formData = new FormData();
        const filename = `voice_${Date.now()}.webm`;
        formData.append('media', audioBlob, filename);
        formData.append('msg', 'üéµ Voice message');

        // Send to server via HTTP
        const response = await fetch(`/chat/${otherUserId}`, {
          method: 'POST',
          body: formData
        });

        if (response.ok) {
          console.log('‚úÖ Voice message sent successfully via HTTP');
          hideVoiceRecordingModal();

          // Also send via Socket.IO for real-time update
          const arrayBuffer = await audioBlob.arrayBuffer();
          const roomId = [currentUserId, otherUserId].sort().join('_');

          chatSocket.emit('voiceMessage', {
            roomId: roomId,
            from: currentUserId,
            to: otherUserId,
            audio: arrayBuffer,
            filename: filename,
            mimeType: audioBlob.type,
            timestamp: Date.now()
          });

          console.log('üì© Voice message sent via Socket.IO for real-time update');

        } else {
          throw new Error(`Server responded with ${response.status}`);
        }

      } catch (error) {
        console.error('‚ùå Error sending voice message:', error);
        alert('Failed to send voice message: ' + error.message);
        hideVoiceRecordingModal();
      }
    }

    // Initialize voice messages when DOM is ready
    document.addEventListener('DOMContentLoaded', function() {
      initializeVoiceMessages();

      // Also initialize when new messages are added dynamically
      const observer = new MutationObserver(function(mutations) {
        mutations.forEach(function(mutation) {
          if (mutation.type === 'childList') {
            mutation.addedNodes.forEach(function(node) {
              if (node.nodeType === 1 && node.querySelector) {
                const newVoiceButtons = node.querySelectorAll('.voice-play-btn');
                newVoiceButtons.forEach(button => {
                  if (!button.hasEventListener) {
                    const audioSrc = button.dataset.audioSrc;
                    button.addEventListener('click', function() {
                      toggleVoiceMessage(this, audioSrc);
                    });
                    button.hasEventListener = true;
                  }
                });
              }
            });
          }
        });
      });

      const messagesContainer = document.getElementById('messages-container');
      if (messagesContainer) {
        observer.observe(messagesContainer, {
          childList: true,
          subtree: true
        });
      }
    });
  </script>
</body>
</html>